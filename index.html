<!doctype html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>COMPSCI 690: Trustworthy and Responsible AI (TRAI) Syllabus</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css" />
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Source+Sans+3:wght@300;400;500;600&family=Source+Serif+4:ital,wght@0,400;0,600;1,400&display=swap" />
    <link rel="shortcut icon" type="image/png" href="../assets/images/favicon.ico" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" />
    <style>
        :root {
            --primary-color: #3273dc;
            --secondary-color: #1a7caa;
            --accent-color: #48c774;
            --text-color: #363636;
            --light-bg: #f5f7fa;
            --border-color: #eaeaea;
        }
        body {
            font-family: "Source Sans 3", -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen-Sans, Ubuntu, Cantarell, "Helvetica Neue", sans-serif;
            color: var(--text-color);
            line-height: 1.6;
            background-color: #ffffff;
        }
        .title, h1, h2, h3, h4, h5, h6 {
            font-family: "Source Serif 4", Georgia, serif;
            font-weight: 600;
            color: #222;
            line-height: 1.2;
        }
        /* Using Bulma's responsive container classes instead of fixed width */
        .section {
            padding: 2.5rem 1.5rem;
        }
        .section-nav {
            position: sticky;
            top: 0;
            background-color: rgba(255, 255, 255, 0.95);
            border-bottom: 1px solid var(--border-color);
            z-index: 100;
            margin-bottom: 2rem;
        }
        .nav-container {
            display: flex;
            justify-content: center;
            gap: 0.5rem;
        }
        .nav-item {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.75rem 1.25rem;
            border-radius: 6px;
            text-decoration: none;
            color: var(--text-color);
            font-weight: 500;
            transition: all 0.3s ease;
            border: 1px solid transparent;
        }
        .nav-item:hover, .nav-item.active {
            background-color: var(--secondary-color);
            color: white;
            border-color: var(--secondary-color);
        }
        .content ul {
            list-style-type: disc;
            margin-left: 1.5rem;
        }
        .content ul li {
            margin-bottom: 0.5rem;
        }
        .reading-row {
            background-color: #f8f9fa !important;
            font-size: 0.9em;
            color: #666;
        }
        .reading-row td {
            padding-left: 2rem !important;
            padding-top: 0.25rem !important;
            padding-bottom: 0.25rem !important;
            border-top: none !important;
        }
        .footer {
            background-color: var(--light-bg);
            padding: 2rem 1.5rem;
            font-size: 0.9rem;
        }
        
        /* Assignment Sidebar */
        .assignment-sidebar {
            position: fixed;
            right: 0;
            top: 100px;
            width: 220px;
            background-color: white;
            border-left: 2px solid var(--border-color);
            padding: 1.5rem 1rem;
            max-height: calc(100vh - 120px);
            overflow-y: auto;
            z-index: 50;
            box-shadow: -2px 0 10px rgba(0,0,0,0.05);
        }
        
        .assignment-sidebar h4 {
            font-size: 0.9rem;
            font-weight: 600;
            color: var(--text-color);
            margin-bottom: 1rem;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }
        
        .assignment-nav-list {
            list-style: none;
            margin: 0;
            padding: 0;
        }
        
        .assignment-nav-list li {
            margin-bottom: 0.5rem;
        }
        
        .assignment-nav-link {
            display: block;
            padding: 0.6rem 0.8rem;
            color: var(--text-color);
            text-decoration: none;
            border-radius: 6px;
            font-size: 0.9rem;
            transition: all 0.3s ease;
            border-left: 3px solid transparent;
        }
        
        .assignment-nav-link:hover {
            background-color: var(--light-bg);
            border-left-color: var(--secondary-color);
            padding-left: 1rem;
        }
        
        .assignment-nav-link.active {
            background-color: var(--secondary-color);
            color: white;
            border-left-color: var(--accent-color);
        }
        
        .main-content {
            margin-right: 240px;
        }
        
        @media screen and (max-width: 1200px) {
            .assignment-sidebar {
                display: none;
            }
            .main-content {
                margin-right: 0;
            }
        }
        
        @media screen and (max-width: 768px) {
            .section { padding: 1.5rem 0.5rem; }
            .nav-container { gap: 0.25rem; }
            .nav-item { padding: 0.6rem 0.8rem; font-size: 0.95rem; }
        }
        
            /* new assignment tweaks */
    #week3-assignment1 .content ul li,
    #week3-assignment1 ul li {
      margin-bottom: 0.35rem;
    }
    #week3-assignment1 .box ul li {
      margin-bottom: 0.3rem;
    }

    </style>
</head>
<body>
    <!-- Assignment Sidebar -->
    <aside class="assignment-sidebar">
        <h4>Assignments</h4>
        <ul class="assignment-nav-list">
            <li><a href="#week2-startup" class="assignment-nav-link">Week 2 - Startup Ideas</a></li>
            <li><a href="#week3-assignment1" class="assignment-nav-link">Assignment 1</a></li>
            <li><a href="#week4-assignment2" class="assignment-nav-link">Assignment 2</a></li>
            <li><a href="#week5-assignment3" class="assignment-nav-link">Assignment 3</a></li>
            <li><a href="#week6-assignment4" class="assignment-nav-link">Assignment 4</a></li>
            <li><a href="#week7-assignment5" class="assignment-nav-link">Assignment 5</a></li>
            <li><a href="#week8-assignment6" class="assignment-nav-link">Assignment 6</a></li>
            <li><a href="#week9-assignment7" class="assignment-nav-link">Assignment 7</a></li>

          </ul>
    </aside>

    <nav class="section-nav">
        <div class="nav-container">
            <a href="#overview" class="nav-item active">Overview</a>
            <a href="#expectations" class="nav-item">Expectations</a>
            <a href="#grading" class="nav-item">Grading</a>
            <a href="#syllabus" class="nav-item">Syllabus</a>
            <a href="#project" class="nav-item">Project</a>
            <a href="#assignments" class="nav-item">Assignments</a>
            <a href="#policies" class="nav-item">Policies</a>
        </div>
    </nav>
    <section class="section main-content">
        <div class="container is-widescreen">
            <h1 class="title is-2" id="overview">CS 690: Trustworthy and Responsible AI</h1>
            <div class="content">
                <p><strong>Instructor:</strong> <a href="https://people.cs.umass.edu/~eugene/"  target="_blank">Eugene Bagdasaryan</a><br>
                <strong>TA:</strong> <a href="https://hyejunjeong.github.io/" target="_blank">June Jeong</a><br>
                <strong>Time:</strong> MoWe 2:30PM - 3:45PM<br>
                <strong>Location:</strong> Computer Science Bldg rm 142<br>
                <strong>Office hours:</strong> Eugene: Wed 4-5pm by
                <a href="https://calendar.app.google/4Hc4KpSgxhSZHyYH8">appointment</a> , CS 304 | June: Fri 2-4pm by <a
                href="https://calendar.app.google/nV4TxaSR2MAPB6Es6"
                target="_blank">appointment</a> , CS 207<br>
                </p>
                <p>In the era of intelligent assistants, autonomous agents, and self-driving cars we expect AI systems to not cause harm and withstand adversarial attacks. In this course you will learn advanced methods of building AI models and systems that mitigate privacy, security, societal, and environmental risks. We will go deep into attack vectors and what type of guarantees current research can and cannot provide for modern generative models. The course will feature extensive hands-on experience with model training and regular discussion of key research papers. <strong>Students are required to have taken NLP, general ML, and security classes before taking this course.</strong></p>
            </div>

            <h2 class="title is-4 mt-5" id="expectations">Expectations</h2>
            <div class="content">
                <ul>
                    <li>Required reading, attendance, and participation</li>
                    <li>Each group: weekly presentation + code for assignments</li>
                    <li>Group research project</li>
                </ul>
            </div>

            <h2 class="title is-4 mt-5" id="grading">Grading Breakdown</h2>
            <div class="content">
                <div class="columns">
                    <div class="column is-8">
                        <table class="table is-bordered is-striped is-narrow is-hoverable is-fullwidth">
                            <thead>
                                <tr>
                                    <th>Component</th>
                                    <th>Percentage</th>
                                    <th>Details</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td><strong>Attendance</strong></td>
                                    <td>10%</td>
                                    <td>Allowed to miss any 4 classes</td>
                                </tr>
                                <tr>
                                    <td><strong>Assignments (slides + report + code)</strong></td>
                                    <td>40%</td>
                                    <td>2 total (20% each), allowed 1
                                    late day per assignment.</td>
                                </tr>
                                <tr>
                                    <td><strong>Final Project</strong></td>
                                    <td>50%</td>
                                    <td>
                                        <ul>
                                            <li>1-page Proposal (10%)</li>
                                            <li>Mid-Semester Presentation (5%)</li>
                                            <li>Final Report (20%)</li>
                                            <li>Final Presentation (15%)</li>
                                        </ul>
                                    </td>
                                </tr>
                                <tr>
                                    <td><strong>(Optional) bonus</strong></td>
                                    <td>up to 5%</td>
                                    <td>Active participation, excellent code implementation, slide efforts</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                </div>
            </div>

            

            <h2 class="title is-4 mt-5" id="syllabus">Syllabus: Weekly Schedule</h2>
            <div class="content">
                <style>
                    .week-color-1 { background-color: rgba(230, 240, 255, 0.5); }
                    .week-color-2 { background-color: rgba(255, 250, 240, 0.5); }
                    .reading-row { background-color: transparent !important; }
                    .reading-row.week-color-1 { background-color: rgba(230, 240, 255, 0.3) !important; }
                    .reading-row.week-color-2 { background-color: rgba(255, 250, 240, 0.3) !important; }
                </style>
                
                <table class="table is-fullwidth">
                  <caption class="has-text-weight-semibold" style="caption-side: top; text-align: left; padding-bottom: 0.5em;">Fall 2025 Class Schedule</caption>
                  <thead>
                    <tr>
                      <th>Week</th>
                      <th>Class #</th>
                      <th>Date</th>
                      <th>Topic</th>
                      <th>Notes</th>
                      <th>Links/Slides/Assignments</th>
                    </tr>
                  </thead>
                  <tbody>
                   <tr class="week-color-1"><td>Week 1</td><td>1</td><td>Wed, Sep 3</td><td>Intro + Project group formations</td><td>First Day of Classes</td><td><a href="#week2-startup">Bonus Assignment: Startup ideas</a></td></tr>
<tr class="reading-row week-color-1"><td></td><td></td><td></td><td>No reading</td><td></td><td></td></tr>

                   <!-- <tr class="reading-row"><td></td><td></td><td>📖 Paper 1: <a href="https://doi.org/10.48550/arXiv.1802.07228">The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation</a></td><td></td><td></td></tr>
<tr class="reading-row"><td></td><td></td><td>📖 Paper 2: <a href="https://doi.org/10.48550/arXiv.1610.02413">Equality of Opportunity in Supervised Learning</a></td><td></td><td></td></tr>
<tr class="reading-row"><td></td><td></td><td>📖 Paper 3: <a href="https://doi.org/10.48550/arXiv.1906.02243">Energy and Policy Considerations for Deep Learning in NLP</a></td><td></td><td></td></tr> -->

<tr class="week-color-2"><td>Week 2</td><td>2</td><td>Mon, Sep 8</td><td>Overview Privacy and Security</td><td><a href=https://docs.google.com/presentation/d/1SRfDoP_U0G9d50pYSWVqI7luRFAHV6QxXDyTZ5hHVdM/edit?usp=sharing>Slides</a></td><td><a href="#week3-assignment1">Assignment 1 Release (Due 9/19)</a></td></tr>
<tr class="reading-row week-color-2"><td></td><td></td><td></td><td>📖 Paper 1: <a href="https://arxiv.org/abs/1611.03814">Towards the Science of Security and Privacy in Machine Learning</a></td><td></td><td></td></tr>
<!-- <tr class="reading-row week-color-2"><td></td><td></td><td></td><td><strong>Part 1, Assignment 1:</strong> Build synthetic data</td><td></td><td></td></tr> -->

<tr class="week-color-2"><td></td><td>3</td><td>Wed, Sep 10</td><td>Privacy. Membership Inference Attacks</td><td><a href=https://docs.google.com/presentation/d/1t-Wpj6FBOesstc5jtYccKieG2vf9sHSjDNMU-etpNeo/edit?usp=sharing>Slides</a></td><td></td></tr>
<tr class="reading-row week-color-2"><td></td><td></td><td></td><td>📖 Paper 1: <a href="https://arxiv.org/abs/2112.03570">Membership Inference Attacks From First Principles</a></td><td></td><td></td></tr>
<tr class="reading-row week-color-2"><td></td><td></td><td></td><td>📖 Paper 2: <a href="https://arxiv.org/abs/1610.05820">Membership Inference Attacks against Machine Learning Models</a></td><td></td><td></td></tr>
<!-- <tr class="reading-row week-color-2"><td></td><td></td><td></td><td><strong>Part 2, Assignment 1:</strong> Build synthetic data</td><td></td><td></td></tr> -->

<tr class="week-color-1"><td>Week 3</td><td>4</td><td>Mon, Sep 15</td><td>Privacy. Training Data Attacks</td><td>Last day to add/drop (Grad)</td><td></td></tr>
<tr class="reading-row week-color-1"><td></td><td></td><td></td><td>📖 Paper 1: <a href="https://arxiv.org/abs/2012.07805">Extracting Training Data from Large Language Models</a></td><td></td><td></td></tr>
<tr class="reading-row week-color-2"><td></td><td></td><td></td><td>📖 Paper 2: <a href="https://arxiv.org/abs/2503.17514">Language Models May Verbatim Complete Text They Were Not Explicitly Trained On</a></td><td></td><td></td></tr>
<tr class="reading-row week-color-2"><td></td><td></td><td></td><td>📖 Paper 3: <a href="https://arxiv.org/abs/2409.19798">Membership Inference Attacks Cannot Prove that a Model Was Trained On Your Data</a></td><td></td><td></td></tr>
<tr class="reading-row week-color-2"><td></td><td></td><td></td><td>📖 Paper 4: <a href="https://arxiv.org/abs/2004.15015">Imitation Attacks and Defenses for Black-box Machine Translation Systems</a></td><td></td><td></td></tr>
<!-- <tr class="reading-row week-color-1"><td></td><td></td><td></td><td><strong>Part 1, Assignment 2:</strong> Show attacks → train + reconstruction</td><td></td><td></td></tr> -->

<tr class="week-color-1"><td></td><td>5</td><td>Wed, Sep 17</td><td>Privacy. Federated Learning</td><td></td><td><a href="#week4-assignment2">Assignment 2 Release (Due 9/26)</a></td></tr>
<tr class="reading-row week-color-1"><td></td><td></td><td></td><td>📖 Paper 1: <a href="https://arxiv.org/abs/1602.05629">Communication-Efficient Learning of Deep Networks from Decentralized Data</a></td><td></td><td></td></tr>
<tr class="reading-row week-color-1"><td></td><td></td><td></td><td>📖 Paper 2: <a href="https://arxiv.org/abs/1912.04977">Advances and Open Problems in Federated Learning</a></td><td></td><td></td></tr>

<tr class="week-color-1"><td></td><td></td><td>Fri, Sep 19</td><td></td><td></td><td><strong>Assignment 1:</strong> Synthetic data + reconstruction</td></tr>
<!-- <tr class="reading-row -->
<!-- week-color-1"><td></td><td></td><td></td><td><strong>Assignment 1. Due Sep 19:</strong> Synthetic data. Show attacks → train +
reconstruction</td><td></td><td></td></tr> -->


<tr class="week-color-2"><td>Week 4</td><td>6</td><td>Mon, Sep 22</td><td>Privacy. Differential Privacy, Part 1. Basics</td><td></td><td></td></tr>
<tr class="reading-row week-color-2"><td></td><td></td><td></td><td>📖
Paper 1: <a href="https://arxiv.org/abs/1607.00133">Deep Learning with
Differential Privacy</a></td><td></td><td></td></tr>
<tr class="reading-row week-color-2"><td></td><td></td><td></td><td>📖 Paper 2: <a href="https://arxiv.org/abs/2501.18914">Scaling Laws for Differentially Private Language Models</a></td><td></td><td></td></tr>
<!-- <tr class="reading-row week-color-2"><td></td><td></td><td></td><td><strong>Part 1, Assignment 3:</strong> Implement Federated Learning</td><td></td><td></td></tr> -->

<tr class="week-color-2"><td></td><td>7</td><td>Wed, Sep 24</td><td>Privacy. Differential Privacy, Part 2. In-Context Learning, Private Evolution</td><td></td><td><a href="#week5-assignment3">Assignment 3 Release (Due 10/3)</a></td></tr>
<tr class="reading-row week-color-2"><td></td><td></td><td></td><td>📖 Paper 1: <a href="https://arxiv.org/abs/2305.15560">Differentially Private Synthetic Data via Foundation Model APIs 1: Images</a></td><td></td><td></td></tr>
<tr class="reading-row week-color-2"><td></td><td></td><td></td><td>📖 Paper 2: <a href="https://arxiv.org/abs/1710.06963">Learning Differentially Private Recurrent Language Models</a></td><td></td><td></td></tr>

<!-- <tr class="reading-row week-color-2"><td></td><td></td><td></td><td><strong>Part 2, Assignment 3:</strong> Implement Federated Learning</td><td></td><td></td></tr> -->
<tr class="week-color-2"><td></td><td></td><td>Fri, Sep 26</td><td></td><td></td><td><strong>Assignment 2:</strong> Federated Learning</td></tr>

<tr class="week-color-1"><td>Week 5</td><td>8</td><td>Mon, Sep 29</td><td>Privacy. Data Analytics, PII Filtering with LLMs</td><td></td><td><a href="#week6-assignment4">Assignment 4 Release (Due 10/10)</a></td></tr>
<tr class="reading-row week-color-1"><td></td><td></td><td></td><td>📖
Paper 1: <a href="https://arxiv.org/abs/2310.07298">Beyond
Memorization: Violating Privacy Via Inference with Large Language
Models</a></td><td></td><td></td></tr>
<tr class="reading-row week-color-1"><td></td><td></td><td></td><td>📖 Paper 2: <a href="https://arxiv.org/abs/2505.14549">Can Large Language Models Really Recognize Your Name?</a></td><td></td><td></td></tr>
<!-- <tr class="reading-row week-color-1"><td></td><td></td><td></td><td><strong>Part 1, Assignment 4:</strong> Implement Differential Privacy or Private Evolution</td><td></td><td></td></tr> -->

<tr class="week-color-1"><td></td><td>9</td><td>Wed, Oct 1</td><td>Privacy. Contextual Integrity</td><td></td><td></td></tr>
<tr class="reading-row week-color-1"><td></td><td></td><td></td><td>📖 Paper 1: <a href="https://arxiv.org/abs/2310.17884">Can LLMs Keep a Secret? Testing Privacy Implications of Language Models via Contextual Integrity Theory</a></td><td></td><td></td></tr>
<tr class="reading-row week-color-1"><td></td><td></td><td></td><td>📖 Paper 2: <a href="https://arxiv.org/abs/2405.05175">AirGapAgent: Protecting Privacy-Conscious Conversational Agents</a></td><td></td><td></td></tr>
<!-- <tr class="reading-row week-color-1"><td></td><td></td><td></td><td><strong>Part 2, Assignment 4:</strong> Implement Differential Privacy or Private Evolution</td><td></td><td></td></tr> -->
<tr class="week-color-1"><td></td><td></td><td>Fri, Oct 3</td><td></td><td></td><td><strong>Assignment 3:</strong> Differential Privacy</td></tr>

<tr class="week-color-2"><td>Week 6</td><td>10</td><td>Mon, Oct
6</td><td>Guest Talk (Amer Sinha) + Future Directions
Discussions</td><td></td><td></td></tr>
<tr class="reading-row week-color-2"><td></td><td></td><td></td><td>No paper reading</td><td></td><td></td></tr>
<!-- <tr class="reading-row week-color-2"><td></td><td></td><td></td><td><strong>Part 1+2, Assignment 5:</strong> PII filtering + CI → airgap, context hijacking</td><td></td><td></td></tr> -->


<tr class="week-color-2"><td></td><td>11</td><td>Wed, Oct 8</td><td><strong>Mid-Semester Project Presentations (All Teams)</strong></td><td></td>
<td><a
href="#midterm-annc">Instructions</a></td></tr>
<tr class="reading-row week-color-2"><td></td><td></td><td></td><td>No paper reading</td><td></td><td></td></tr>
<tr class="week-color-2"><td></td><td></td><td>Fri, Oct 10</td><td></td><td></td><td><strong>Assignment 4:</strong> PII Extraction <br><strong>Project Proposal</strong> to Gradescope</td></tr>

<tr class="week-color-1"><td>Week 7</td><td>12</td><td>Mon, Oct 13</td><td></td><td><strong>Holiday - Indigenous People's Day (No Class)</strong></td><td></td></tr>

<tr class="week-color-1"><td></td><td>13</td><td>Wed, Oct 15</td><td>No class. Project work</td><td></td><td></td></tr>
<tr class="reading-row week-color-1"><td></td><td></td><td></td><td>No paper reading</td><td></td><td></td></tr>
<tr class="week-color-1"><td></td><td></td><td>Fri, Oct 17</td><td></td><td></td><td><strong>Assignment 5:</strong> Contextual Integrity<br><a href="#week8-assignment6">Assignment 6 Release (Due 10/24)</a></td></tr>

<tr class="week-color-2"><td>Week 8</td><td>14</td><td>Mon, Oct
20</td><td>Security. Jailbreaks + Prompt injections</td><td></td><td></td></tr>
<tr class="reading-row week-color-2"><td></td><td></td><td></td><td>📖 Paper 1: <a href="https://arxiv.org/abs/2307.15043">Universal and Transferable Adversarial Attacks on Aligned Language Models</a></td><td></td><td></td></tr>
<tr class="reading-row week-color-2"><td></td><td></td><td></td><td>📖 Paper 2: <a href="https://arxiv.org/abs/2302.12173">Not what you've signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection</a></td><td></td><td></td></tr>


<tr class="week-color-2"><td></td><td>15</td><td>Wed, Oct
22</td><td>Assignments 4, 5, 6 Presentations.</td><td></td><td></td></tr>
<!-- <tr class="reading-row week-color-2"><td></td><td></td><td></td><td></td><td></td><td></td></tr> -->
<tr class="week-color-2"><td></td><td></td><td>Fri, Oct 24</td><td></td><td></td><td><strong>Assignment 6:</strong> Jailbreaking and prompt injections</td></tr>

<tr class="week-color-1"><td>Week 9</td><td>16</td><td>Mon, Oct 27</td><td>Security. Adversarial Examples in Multi-modal systems</td><td></td><td></td></tr>
<tr class="reading-row week-color-1"><td></td><td></td><td></td><td>📖 Paper 1: <a href="https://arxiv.org/abs/2306.15447">Are aligned neural networks adversarially aligned?</a></td><td></td><td></td></tr>
<tr class="reading-row week-color-1"><td></td><td></td><td></td><td>📖 Paper 2: <a href="https://arxiv.org/abs/2407.08970">Self-interpreting Adversarial Images</a></td><td></td><td></td></tr>
<!-- <tr class="reading-row week-color-1"><td></td><td></td><td></td><td><strong>Assignment 7:</strong> Multi-modal attacks</td><td></td><td></td></tr> -->

<tr class="week-color-1"><td></td><td>17</td><td>Wed, Oct 29</td><td>Security. Poisoning and Backdoors</td><td></td><td></td></tr>
<tr class="reading-row week-color-1"><td></td><td></td><td></td><td>📖 Paper 1: <a href="https://arxiv.org/abs/1807.00459">How To Backdoor Federated Learning</a></td><td></td><td></td></tr>
<!-- <tr class="reading-row week-color-1"><td></td><td></td><td></td><td><strong>Assignment 8:</strong> Backdoors</td><td></td><td></td></tr> -->
<tr class="week-color-1"><td></td><td></td><td>Fri, Oct 31</td><td></td><td></td><td><strong>Assignment 7:</strong> Multi-modal attacks</td></tr>

<tr class="week-color-2"><td>Week 10</td><td>18</td><td>Mon, Nov 3</td><td>Security. Watermarks</td><td></td><td></td></tr>
<tr class="reading-row week-color-2"><td></td><td></td><td></td><td>📖 Paper 1: <a href="https://arxiv.org/abs/2411.18479">SoK: Watermarking for AI-Generated Content</a></td><td></td><td></td></tr>

<tr class="week-color-2"><td></td><td>19</td><td>Wed, Nov 5</td><td>Security. Alignment Attacks</td><td></td><td></td></tr>
<tr class="reading-row week-color-2"><td></td><td></td><td></td><td>📖 Paper 1: <a href="https://arxiv.org/abs/2502.17424v2">Emergent Misalignment: Narrow finetuning can produce broadly misaligned LLMs</a></td><td></td><td></td></tr>
<!-- <tr class="reading-row week-color-2"><td></td><td></td><td></td><td><strong>Assignment 9:</strong> Alignment attacks + RLHF</td><td></td><td></td></tr> -->
<tr class="week-color-2"><td></td><td></td><td>Fri, Oct 24</td><td></td><td></td><td><strong>Assignment 8:</strong> Backdoors</td></tr>

<tr class="week-color-1"><td>Week 11</td><td>20</td><td>Mon, Nov 10</td><td>Security. Principled Defenses</td><td></td><td></td></tr>
<tr class="reading-row week-color-1"><td></td><td></td><td></td><td>📖 Paper 1: <a href="https://arxiv.org/abs/2503.18813">Defeating Prompt Injections by Design</a></td><td></td><td></td></tr>
<tr class="reading-row week-color-1"><td></td><td></td><td></td><td>📖 Paper 2: <a href="https://arxiv.org/abs/2501.17070">Contextual Agent Security</a></td><td></td><td></td></tr>

<tr class="week-color-1"><td></td><td>21</td><td>Wed, Nov 12</td><td>Security. Student Panel + Future Directions</td><td></td><td></td></tr>
<tr class="reading-row week-color-1"><td></td><td></td><td></td><td>No paper reading</td><td></td><td></td></tr>
<tr class="week-color-1"><td></td><td></td><td>Fri, Nov 14</td><td></td><td></td><td><strong>Assignment 9:</strong> Alignment attacks + RLHF</td></tr>

<tr class="week-color-2"><td>Week 12</td><td>22</td><td>Mon, Nov 17</td><td>Societal. Model Fairness and Biases</td><td></td><td></td></tr>
<tr class="reading-row week-color-2"><td></td><td></td><td></td><td>📖 Paper 1: <a href="https://arxiv.org/abs/1905.12101">Differential Privacy Has Disparate Impact on Model Accuracy</a></td><td></td><td></td></tr>

<tr class="week-color-2"><td></td><td>23</td><td>Wed, Nov 19</td><td>Societal. Propaganda, Misinformation, and Deception</td><td></td><td></td></tr>
<tr class="reading-row week-color-2"><td></td><td></td><td></td><td>📖 Paper 1: <a href="https://arxiv.org/abs/2112.05224">Propaganda-as-a-service</a></td><td></td><td></td></tr>
<tr class="week-color-2"><td></td><td></td><td>Fri, Nov 21</td><td></td><td></td><td><strong>Assignment 10:</strong> Resource overhead attacks</td></tr>

<tr class="week-color-1"><td>Week 13</td><td>24</td><td>Mon, Nov 24</td><td>No class. Project work</td><td></td><td></td></tr>
<tr class="reading-row week-color-1"><td></td><td></td><td></td><td>No paper reading</td><td></td><td></td></tr>

<tr class="week-color-1"><td></td><td>25</td><td>Tue, Nov 25</td><td></td><td><strong>Thanksgiving recess begins after last class</strong></td><td></td></tr>

<tr class="week-color-2"><td>Week 14</td><td>26</td><td>Mon, Dec 1</td><td>Environmental. Resource Overhead Attacks</td><td>Classes resume</td><td></td></tr>
<tr class="reading-row week-color-2"><td></td><td></td><td></td><td>📖 Paper 1: <a href="https://arxiv.org/abs/2502.02542">OverThink: Slowdown Attacks on Reasoning LLMs</a></td><td></td><td></td></tr>
<!-- <tr class="reading-row week-color-2"><td></td><td></td><td></td><td><strong>Assignment 10:</strong> Resource overhead attacks</td><td></td><td></td></tr> -->

<tr class="week-color-2"><td></td><td>27</td><td>Wed, Dec 3</td><td>Final Project Presentations. Part 1.</td><td></td><td></td></tr>
<tr class="reading-row week-color-2"><td></td><td></td><td></td><td>No paper reading</td><td></td><td></td></tr>


<tr class="week-color-1"><td>Week 15</td><td>28</td><td>Mon, Dec 8</td><td>Final Project Presentations. Part 2.</td><td></td><td></td></tr>
<tr class="reading-row week-color-1"><td></td><td></td><td></td><td>No paper reading</td><td></td><td></td></tr>

                  </tbody>
                </table>
            </div>

            <h2 class="title is-5 mt-4"  id="project">Group Project</h2>
            <div class="content">
                <div class="box p-5" style="background-color: #f8fafc; border-left: 4px solid var(--secondary-color);">
                    <h4 class="title is-6 mb-3">Instructions for Your Project</h4>
                    <p>You will design an AI Startup and try to defend it against attacks.</p>
                    
                    <p><strong>Pre-requisites:</strong></p>
                    <ul>
                        <li>You need to operate on customer data, i.e. users, companies</li>
                        <li>Your product should use LLMs</li>
                        <li>Your product operates with external parties, i.e. customers, vendors, etc.</li>
                    </ul>
                    
                    <p><strong>Example projects:</strong></p>
                    <ul>
                        <li>Customer support bot</li>
                        <li>AI Tutor</li>
                        <li>Business assistant</li>
                        <li>...</li>
                    </ul>
                    
                    <p>Throughout the semester you will add privacy and security features, building a comprehensive analysis of your project.</p>
                    
                    <p>Additionally, you will need to pick one of the research topics you are interested in and write an
                    extensive research report on it.</p>
                    
                    <p>Make sure to track your own contributions through Git commits (both code and reports).</p>
                </div>

                <div id="midterm-annc" class="box p-5 mt-4" style="background-color:#eef6ff; border-left:4px solid var(--primary-color);">
                  <h4 class="title is-6 mb-2">Announcement — Mid-Semester Presentations</h4>
                  <p class="mb-2"><strong>When:</strong> <span class="has-text-weight-semibold">Wed, Oct 8</span> (entire class, 1h 45m)</p>
                  <p class="mb-3"><strong>Format:</strong> 10 teams · <em>6 min talk + 2 min Q&A</em> per team (≈ 8 min/slot). Please keep slides visual and concise (5–6 slides max).</p>
                  <ul class="mb-3">
                    <li><strong>What to cover:</strong> 
                      <ul>
                        <li><strong>Project title and a brief tagline</strong></li>
                        <li><strong>Problem and motivation:</strong> why this topic matters</li>
                        <li><strong>Startup scenario or application context (if relevant):</strong> what the system does, what the usecases are, who the users are, and what data it handles</li>
                        <li><strong>Threat model or research question:</strong> key privacy/security risks you aim to investigate</li>
                        <li><strong>Experiment plan:</strong> what you plan to evaluate and how</li>
                        <li><strong>Planned defenses &amp; evaluation ideas:</strong></li>
                        <li><strong>Next steps &amp; open questions:</strong> points you want feedback on</li>
                      </ul>
                    <li><strong>Slides:</strong> Add to the shared class deck <em>before class</em>. </li>
                    <li><strong>Policy:</strong> Use only synthetic/sanitized examples; no real PII on slides or demos.</li>
                  </ul>
                  <p class="mb-1"><strong>Follow-up:</strong> Submit the <strong>1-page proposal</strong> by <span class="has-text-weight-semibold">Fri, Oct 10 (EOD)</span>, incorporating in-class feedback.</p>
                </div>

                </div>



                <h2 class="title is-4 mt-5" id="assignments">Assignments</h2>

                <div class="content">
                <h3 class="title is-5 mt-4">All Assignments Overview</h3>
                <ol>
                    <li>Build synthetic data + Show attacks (MIA or data extraction) → reconstruction</li>
                    <li>Implement Federated Learning</li>
                    <li>Implement Differential Privacy and Private Evolution</li>
                    <li>PII filtering/extraction</li>
                    <li>Contextual Integrity → airgap, context hijacking</li>
                    <li>Jailbreaking and prompt injections</li>
                    <li>Multi-modal attacks</li>
                    <li>Backdoors and watermarking </li>
                    <li>Alignment attacks + RLHF</li>
                    <li>Resource overhead attacks</li>
                </ol>
                <h3 class="title is-5 mt-4">Assignment Process</h3>
                <div class="content">
                <ol>
                    <li><strong>Create your repository:</strong> Each team must create a repository on GitHub.</li>
                    <li><strong>Share access:</strong> Add the teaching staff as collaborators.</li>
                    <li><strong>Roles:</strong>
                    <ul>
                        <li>One <em>lead author</em> writes the report and conducts the main experiments.</li>
                        <li>Other team members advise and consult.</li>
                        <li>The lead author receives <strong>80%</strong> of the grade, other members receive <strong>20%</strong>.</li>
                    </ul>
                    </li>
                </ol>

                <h4 class="title is-6 mt-4">Structure of Each Assignment</h4>
                <ul>
                    <li><strong>Reading Report:</strong> Summarize, critique, and connect the assigned papers to your project. <br><em>Include key discussion points from class as well.</em></li>
                    <li><strong>Code:</strong> Implement the required attacks/defenses, include documentation and results.</li>
                    <li><strong>Presentation:</strong> Prepare a short slide deck summarizing your findings.</li>
                </ul>

                <h4 class="title is-6 mt-4">Deadlines & Presentations</h4>
                <ul>
                    <li><strong>Due:</strong> Slide deck, reading report, and code are due <em>Friday of that week, 11:59 PM EST</em>.</li>
                    <li><strong>Presentation:</strong> Happens at the beginning of the <em>following week’s class</em>.</li>
                </ul>
                </div>
            </div>

<!-- WEEK 2 STARTUP IDEA (clean layout) -->
<div id="week2-startup" class="box p-5 mb-6" style="background-color:#f8fafc; border-left:4px solid var(--accent-color);">
  <header class="is-flex is-justify-content-space-between is-align-items-center mb-3">
    <h3 class="title is-4 mb-0">(Bonus) Week 2 – Startup Ideas & Group Formation</h3>
    <span class="tag is-info is-light is-medium">Not graded · Bonus points for best ideas</span>
  </header>

  <!-- At a glance -->
  <div class="columns is-variable is-5 mb-4">
    <div class="column is-6">
      <div class="box p-4" style="background:white;">
        <h4 class="title is-6 mb-3">At a Glance</h4>
        <ul>
          <li>Paper: <a href="https://arxiv.org/abs/1611.03814">Towards the Science of Security and Privacy in Machine Learning</a></li>
          <li>
            Slide deck: <a href="https://docs.google.com/presentation/d/1yrLf_wToBqQnFK1d1mCMFCo6IW5QKJFV3MYqTs-uNe8/edit?usp=sharing" target="_blank">
              Add Slides here!
            </a>
          </li>
        </ul>
      </div>
    </div>
    <div class="column is-6">
      <div class="box p-4" style="background:white;">
        <h4 class="title is-6 mb-3">Timeline</h4>
        <ul>
          <li><strong>Week 2 class:</strong> Present your startup idea in-class (~5 minutes).</li>
          <li><strong>During class:</strong> Form project groups.</li>
        </ul>
      </div>
    </div>
  </div>

  <!-- Content -->
  <div class="box p-4" style="background:white;">
    <h4 class="title is-6 mb-3">Content</h4>
    <div class="content">
    <ul>
      <li>Present your ideas for a startup for 5 minutes.</li>
      <li>Show how the startup touches on user data and opens up privacy/security challenges.</li>
      <li>Form groups.</li>
      <li>
        Don’t forget about Slack! 
        <a href="https://join.slack.com/t/cs690trustwor-vhd9016/shared_invite/zt-3cho5jdf8-rnmFegIyajqvg4aj9TGMZg" target="_blank">Join here</a>
      </li>
    </ul>
    </div>
    <p class="mt-3"><em>This assignment is not graded! But best ideas will get bonus points.</em></p>
  </div>
</div>

<!-- WEEK 3 ASSIGNMENT (clean layout) -->
<section id="week3-assignment1" class="box p-5 mb-6" style="background:#f8fafc; border-left:4px solid var(--accent-color);">
  <header class="is-flex is-justify-content-space-between is-align-items-center mb-3">
    <h3 class="title is-4 mb-0">Week 3 — Build a Synthetic Dataset & MIA/Extraction Attack</h3>
    <span class="tag is-success is-light is-medium">Due Fri 9/19 · 11:59 PM EST</span>
  </header>

  <!-- At a glance -->
  <div class="columns is-variable is-5 mb-4">
    <div class="column is-6">
      <div class="box p-4" style="background:white;">
        <h4 class="title is-6 mb-3">At a Glance</h4>
        <ul class="mb-2">
          <li>📖 <a href="https://arxiv.org/abs/2112.03570">Membership Inference Attacks From First Principles</a></li>
          <li>Focus: Synthetic data → Train → Attack → (optional) Reconstruct</li>
        </ul>
        <p class="mb-1"><strong>What to submit:</strong></p>
        <ul class="mt-1">
          Slide deck <a href="https://docs.google.com/presentation/d/1csOzyU64TuxK8O7JLB4BYM8rc_wJMfB3r5ZGMo8StXg/edit?usp=sharing" target="_blank">
            (Google Slides link)</a>
          <li>Reading report (PDF) to Gradescope</li>
          <li>Code & dataset to Github Repo</li>
        </ul>
      </div>
    </div>
    <div class="column is-6">
      <div class="box p-4" style="background:white;">
        <h4 class="title is-6 mb-3">Timeline</h4>
        <ul>
          <li><strong>Friday 11:59 PM EST:</strong> slides + reading report + code due</li>
          <li><strong>Next class:</strong> short in-class presentation</li>
        </ul>
      </div>
    </div>
  </div>

  <!-- Reading Report -->
  <h4 class="title is-5 mt-2 mb-3">Reading Report</h4>
  <div class="content">
    <p><strong>Summarize &amp; critique:</strong> 2–3 sentence summary + 1 strength + 1 weakness.</p>
    <div class="columns">
      <div class="column">
        <p class="has-text-weight-semibold mb-2">Connect</p>
        <ul>
          <li>How do MIAs exploit overfitting? How does this connect to your MIA implementation?</li>
          <li>How does data extraction differ from MIAs, and why are LLMs vulnerable?</li>
          <li>Is your dataset vulnerable to MIA? Why?</li>
        </ul>
      </div>
      <div class="column">
        <p class="has-text-weight-semibold mb-2">Discussion</p>
        <ul>
          <li>What properties of training data make extraction more dangerous?</li>
        </ul>
      </div>
    </div>
  </div>

  <hr class="my-5">

  <!-- Coding Assignment -->
  
  <h4 class="title is-5 mb-2">Coding Assignment 1</h4>
  <p class="mb-4"><strong>Goal:</strong> (1) Build a synthetic dataset and train a model. (2) Run a membership inference attack (image) or a training-data extraction demo (text). <em>Bonus:</em> do both.</p>

  <div class="box p-4 mb-4" style="background:white;">
    <h5 class="title is-6 mb-3">Task 1. Build a Synthetic Dataset — Requirements</h5>
    <div class="content">
    <ul>
      <li><strong>Create a realistic synthetic dataset.</strong> Programmatic or manual; small but coherent.</li>
      <li><strong>Any data type:</strong> tabular, text, image, audio, or video (the product should still use an LLM).</li>
      <li><strong>Size &amp; labels:</strong>
        <ul>
          <li>≥ <strong>100</strong> labeled samples.</li>
          <li>Labels suitable for training/testing (class/category).</li>
          <li>Manual sanity-check for coherence and correct labels.</li>
        </ul>
      </li>
      <li><strong>Use-case representation:</strong> realistic privacy-sensitive scenario. Examples:
        <ul>
          <li><em>Tabular:</em> customer transactions, demographics, sensors.</li>
          <li><em>Text:</em> user queries, chatbot logs, search queries.</li>
          <li><em>Image:</em> simple shapes, icons, handwritten digits.</li>
          <li><em>Audio/Video:</em> short labeled clips (optional).</li>
        </ul>
      </li>
    </ul>
    </div>
  </div>

  <div class="box p-4 mb-4" style="background:white;">
    <h5 class="title is-6 mb-3">Task 2. Attack — Requirements</h5>
    <div class="content">
    <ul>
      <li>Train a <strong>baseline model</strong> suitable for your data type.</li>
      <li>Implement <strong>MIA</strong> or <strong>training-data extraction</strong> and report
        <strong>AUC/attack accuracy</strong> or a justified qualitative score.</li>
      <li><strong>Analyze</strong> why attack strength matches (or not) reconstruction quality.</li>
    </ul>
    </div>
  </div>

  <div class="box p-4" style="background:white;">
    <h5 class="title is-6 mb-3">Deliverables (GitHub)</h5>
    <div class="content">
    <ul>
      <li><strong>Dataset file</strong> — CSV (tabular), JSON/TXT (text), or folder (images/audio)</li>
      <li><strong>Attack code</strong></li>
      <li><strong>README</strong> with:
        <ul>
          <li>Dataset (use case, #samples &amp; label distribution, generation method, examples)</li>
          <li>Attack details (design choices, implementation, metrics &amp; results, vulnerability analysis, implications)</li>
        </ul>
      </li>
    </ul>
    </div>
  </div>

  <hr class="my-5">

  <h4 class="title is-5 mb-2">Presentation</h4>
    <div class="content">
    <ul>
        <li><strong>Upload:</strong> Add your slides to the shared 
        <a href="https://docs.google.com/presentation/d/1csOzyU64TuxK8O7JLB4BYM8rc_wJMfB3r5ZGMo8StXg/edit?usp=sharing" target="_blank">
        class slide deck</a>.</li>
        <li><strong>Summary:</strong> Summarize the assigned paper(s) — key contributions, methods, findings.</li>
        <li><strong>Connection:</strong> Relate to your startup/project (threat models, risks, defenses).</li>
        <li><strong>Dataset details:</strong> Briefly explain your synthetic dataset and attack setup.</li>
        <li><strong>Demo:</strong> Code demo: show results on your dataset (success rate, reconstruction quality, and why).</li>
    </ul>
    </div>
</section>

<!-- WEEK 4 ASSIGNMENT (clean layout) -->
<section id="week4-assignment2" class="box p-5 mb-6" style="background:#f8fafc; border-left:4px solid var(--accent-color);">
  <header class="is-flex is-justify-content-space-between is-align-items-center mb-3">
    <h3 class="title is-4 mb-0">Week 4 — Assignment 2: Federated Learning</h3>
    <span class="tag is-success is-light is-medium">Presentation 9/24 · Report & Code Due Fri 9/26 · 11:59 PM ET</span>
  </header>

  <!-- At a glance -->
  <div class="columns is-variable is-5 mb-4">
    <div class="column is-6">
      <div class="box p-4" style="background:white;">
        <h4 class="title is-6 mb-3">At a Glance</h4>
        <ul class="mb-2">
          <li>📖 <a href="https://arxiv.org/abs/1602.05629" target="_blank">Communication-Efficient Learning of Deep Networks from Decentralized Data</a> </li> 
          <li> 📖 <a href="https://arxiv.org/abs/1912.04977" target="_blank">Advances and Open Problems in Federated Learning</a></li>
          <li>Focus: Implement FedAvg (or equivalent), compare to centralized baseline, analyze privacy/comms trade-offs.</li>
        </ul>
        <p class="mb-1"><strong>What to submit:</strong></p>
        <ul class="mt-1">
            <!-- Slide deck <a href="https://docs.google.com/presentation/d/1csOzyU64TuxK8O7JLB4BYM8rc_wJMfB3r5ZGMo8StXg/edit?usp=sharing" target="_blank"> -->
            <!-- (Google Slides link)</a> -->
            Slide deck (add to shared class deck)
          <li>Reading report (PDF) → Gradescope</li>
          <li>Code + README → GitHub repo</li>
        </ul>
      </div>
    </div>
    <div class="column is-6">
      <div class="box p-4" style="background:white;">
        <h4 class="title is-6 mb-3">Timeline</h4>
        <ul>
          <li><strong>Wed 9/24 (in class):</strong> 1–2 min presentation + quick demo</li>
          <li><strong>Fri 9/26 11:59 PM ET:</strong> reading report + code due</li>
        </ul>
      </div>
    </div>
  </div>

  <!-- Presentation -->
  <h4 class="title is-5 mt-2 mb-3">In-Class Presentation (1–2 minutes) (9/24) </h4>
  <div class="content">
    <ul>
      <li><strong>Summary:</strong> 2–3 bullet points from papers (main idea & why it matters).</li>
      <li><strong>Connection:</strong> 1 bullet on how FL relates to your project/startup (threats, risks, defenses).</li>
      <li><strong>Demo:</strong> Show your FL code results (e.g., a training log line or accuracy plot).</li>
      <li><strong>Baseline:</strong> You may include centralized training results for comparison.</li>
    </ul>
  </div>

  <!-- Reading Report -->
  <h4 class="title is-5 mt-2 mb-3">Reading Report (Due 9/26)</h4>
  <div class="content">
    <p><strong>Format:</strong> ~1–1.5 pages (PDF). Combine both papers into one report.</p>
    <p><strong>Summarize &amp; critique:</strong> 2–3 sentence summary + 1 strength + 1 weakness.</p>
    <div class="columns">
      <div class="column">
        <p class="has-text-weight-semibold mb-2">Connect</p>
        <ul>
          <li>What privacy protections does FL claim, and what risks remain?</li>
          <li>What new attack surface does FL introduce?</li>
          <li>Would FL improve privacy for your project? Why/why not?</li>
        </ul>
      </div>
      <div class="column">
        <p class="has-text-weight-semibold mb-2">Discussion</p>
        <ul>
          <li>Is FL primarily a privacy technique or a scalability/availability technique?</li>
        </ul>
      </div>
    </div>
  </div>

  <hr class="my-5">

  <!-- Coding Assignment -->
  <h4 class="title is-5 mb-2">Coding Assignment 2 (Due Thu 9/26)</h4>
  <p class="mb-4"><strong>Goal:</strong> Implement a simple FL pipeline on your synthetic dataset to examine communication, aggregation, and privacy trade-offs.</p>

  <div class="box p-4 mb-4" style="background:white;">
    <h5 class="title is-6 mb-3">Requirements</h5>
    <div class ="content">
    <ul>
      <li>Use ≥ <strong>5 simulated clients</strong> with partitioned subsets (iid or non-iid; describe which).</li>
      <li>Implement <strong>local training</strong> on each client and a <strong>central aggregator</strong> (FedAvg or equivalent).</li>
      <li><strong>Compare FL vs. centralized baseline</strong> on:
        <ul>
          <li>Accuracy</li>
          <li>Convergence speed (rounds/epochs to reach a target accuracy)</li>
          <li>Communication overhead</li>
        <p class="mt-2 mb-0"><strong>Example comms estimate:</strong> <code>Total ≈ 2 × (#params × 4 bytes) × #clients × #rounds</code></p>

        </ul>
      </li>
    </ul>
    </div>
  </div>

  <div class="box p-4 mb-4" style="background:white;">
    <h5 class="title is-6 mb-3">Deliverables (GitHub)</h5>
    <ul>
        <div class="content">
      <li><strong>Code</strong> in your Github Repo</li>
      <li><strong>README.md</strong> can include:
        <ul>
          <li><strong>Design Choices</strong>: number of clients, how did you simulate non-iid, why did you set the number of local epochs as such, etc.</li>
          <li>Model architecture &amp; training details (optimizer, LR, batch size, epochs)</li>
          <li>Dataset description &amp; client partitioning (iid/non-iid, label distribution, sizes)</li>
          <li>Aggregation method &amp; client simulation details (rounds, local epochs, LR, participation rate)</li>
          <li>Performance comparison (tables/plots): accuracy, convergence, communication overhead</li>
          <li>Observed vulnerabilities and implications for your project</li>
        </ul>
      </li>
    </ul>
    </div>
<!-- </div> -->
</section>

<section id="week5-assignment3" class="box p-5 mb-6" style="background:#f8fafc; border-left:4px solid var(--accent-color);">
  <header class="is-flex is-justify-content-space-between is-align-items-center mb-3">
    <h3 class="title is-4 mb-0">Week 5 — Assignment 3: Differential Privacy (DP-SGD)</h3>
    <span class="tag is-success is-light is-medium">Presentation Wed 10/1 · Report & Code Due Fri 10/3 · 11:59 PM ET</span>
  </header>

  <!-- At a glance -->
  <div class="columns is-variable is-5 mb-4">
    <div class="column is-6">
      <div class="box p-4" style="background:white;">
        <h4 class="title is-6 mb-3">At a Glance</h4>
        <ul class="mb-2">
          <li>📖 <a href="https://arxiv.org/abs/1607.00133" target="_blank">Deep Learning with Differential Privacy</a></li>
          <li>📖 <a href="https://arxiv.org/abs/2305.15560" target="_blank">Differentially Private Synthetic Data via Foundation Model APIs: Images</a></li>
          <li>Focus: DP-SGD methods & guarantees, privacy–utility trade-offs, implications for your project.</li>
        </ul>
        <p class="mb-1"><strong>What to submit:</strong></p>
        <ul class="mt-1">
          <li>Slide deck (add to shared class deck)</li>
          <li>Reading report (PDF) → Gradescope</li>
          <li>Code + README → GitHub repo</li>
        </ul>
      </div>
    </div>
    <div class="column is-6">
      <div class="box p-4" style="background:white;">
        <h4 class="title is-6 mb-3">Timeline</h4>
        <ul>
          <li><strong>Wed 10/1 (in class):</strong> 1–2 min presentation + quick DP demo</li>
          <li><strong>Fri 10/3 11:59 PM ET:</strong> reading report + code + README due</li>
        </ul>
      </div>
    </div>
  </div>

  <!-- Presentation -->
  <h4 class="title is-5 mt-2 mb-3">In-Class Presentation (10/1)</h4>
  <div class="content">
    <ul>
      <li><strong>Summary:</strong> Methods (DP-SGD / DP mechanisms), guarantees, and utility costs (2–3 bullets).</li>
      <li><strong>Connection:</strong> Where DP fits in your threat model & deployment scenario.</li>
      <li><strong>Code demo:</strong> Show one DP-SGD run with noise level and <em>ε</em> estimate; note the utility drop.</li>
    </ul>
  </div>

  <!-- Reading Report -->
  <h4 class="title is-5 mt-2 mb-3">Reading Report (Due 10/3)</h4>
  <div class="content">
    <p><strong>Summarize &amp; critique:</strong> 2–3 sentence summary + 1 strength + 1 weakness for each paper.</p>
    <div class="columns">
      <div class="column">
        <p class="has-text-weight-semibold mb-2">Connect</p>
        <ul>
          <li>How does DP mitigate MIA/extraction risks from Week 3?</li>
          <li>How does DP synthetic data extend DP principles? What new risks arise?</li>
        </ul>
      </div>
      <div class="column">
        <p class="has-text-weight-semibold mb-2">Discussion</p>
        <ul>
          <li>When is the privacy–utility trade-off “good enough” for your use case?</li>
          <li>Should synthetic data be evaluated separately for privacy and fairness?</li>
        </ul>
      </div>
    </div>
  </div>

  <hr class="my-5">

  <!-- Coding Assignment -->
  <h4 class="title is-5 mb-2">Coding Assignment 3: Add DP (Training with <span class="is-family-monospace">DP-SGD</span>)</h4>
  <p class="mb-4"><strong>Goal:</strong> Apply <strong>DP-SGD</strong> to your Week-3 pipeline and evaluate privacy & utility.</p>

  <div class="box p-4 mb-4" style="background:white;">
    <h5 class="title is-6 mb-3">Requirements (DP-SGD only)</h5>
    <div class="content">
      <ul>
        <li>Use <strong>per-example clipping</strong> and <strong>Gaussian noise</strong> via <strong>Opacus</strong> or <strong>TF-Privacy</strong>.</li>
        <li><strong>Compute &amp; report</strong> <em>ε(δ)</em> with the library’s accountant (set <em>δ = 1/N</em>).</li>
        <li>Sweep a small grid:
          <ul>
            <li><strong>Clip norm C</strong> ∈ {0.5, 1.0}</li>
            <li><strong>Noise multiplier σ</strong> ∈ {0.5, 1.0, 2.0}</li>
          </ul>
        </li>
        <li>Keep runtime modest (reasonable batch size & epochs); fix other hypers as needed.</li>
        <li>(Optional) Re-run your Week-3 <strong>MIA/extraction</strong> on the best DP setting to show impact.</li>
      </ul>
    </div>
  </div>

  <div class="box p-4 mb-4" style="background:white;">
    <h5 class="title is-6 mb-3">What to Report</h5>
    <div class="content">
      <ul>
        <li><strong>Compare to non-DP baseline</strong> (Week-3 best).</li>
        <li><strong>Effect of hyperparameters</strong></li>
        <li>(Optional) MIA/extraction metric change on best DP setting.</li>
      </ul>
    </div>
  </div>

  <div class="box p-4" style="background:white;">
    <h5 class="title is-6 mb-3">Deliverables (GitHub)</h5>
    <div class="content">
      <ul>
        <li><strong>Code</strong> with DP-SGD enabled (Opacus/TF-Privacy).</li>
        <li><strong>README</strong> can include:
          <ul>
            <li><strong>Design &amp; implementation:</strong> where per-example clipping & noise are applied.</li>
            <li><strong>Settings:</strong> dataset, model, batch size, epochs, <span class="is-family-monospace">C, σ</span>, learning rate, seed(s).</li>
            <li><strong>Results:</strong> table/figure with <em>ε(δ)</em> and utility vs. baseline, effect of hyperparameters.</li>
            <li><strong>Takeaways:</strong> 2–4 bullets about the privacy–utility trade-off for your project.</li>
          </ul>
        </li>
      </ul>
    </div>
  </section>

<section id="week6-assignment4" class="box p-5 mb-6" style="background:#f8fafc; border-left:4px solid var(--accent-color);">
  <header class="is-flex is-justify-content-space-between is-align-items-center mb-3">
    <h3 class="title is-4 mb-0">Week 5 — Assignment 4: PII Filtering</h3>
    <span class="tag is-success is-light is-medium">Presentation Wed 10/22 · Report & Code Due Fri 10/10 · 11:59 PM ET</span>
  </header>

  <!-- At a glance -->
  <div class="columns is-variable is-5 mb-4">
    <div class="column is-6">
      <div class="box p-4" style="background:white;">
        <h4 class="title is-6 mb-3">At a Glance</h4>
        <ul class="mb-2">
          <li>📖 <a href="https://arxiv.org/abs/2310.07298" target="_blank">Beyond Memorization: Violating Privacy via Inference with LLMs</a></li>
          <li>Focus: inference threats vs. memorization; where PII can leak in your pipeline; prototype filter.</li>
        </ul>
        <p class="mb-1"><strong>What to submit:</strong></p>
        <ul class="mt-1">
          <li>Slide deck (present in class 10/22)</li>
          <li>Reading report (PDF) → Gradescope</li>
          <li>Code + README → GitHub repo</li>
        </ul>
      </div>
    </div>
    <div class="column is-6">
      <div class="box p-4" style="background:white;">
        <h4 class="title is-6 mb-3">Timeline</h4>
        <ul>
          <li><strong>Wed 10/22 (in class):</strong> 1–2 min presentation + quick demo</li>
          <li><strong>Fri 10/10 11:59 PM ET:</strong> reading report + code + README due</li>
        </ul>
      </div>
    </div>
  </div>

  <!-- Presentation -->
  <h4 class="title is-5 mt-2 mb-3">In-Class Presentation (10/22)</h4>
  <div class="content">
    <ul>
      <li><strong>Summary:</strong> inference threats vs. memorization (2–3 bullets)</li>
      <li><strong>Connection:</strong> where PII can leak in your pipeline (ingest, logs, prompts, outputs, tools)</li>
      <li><strong>Code demo:</strong> show your prototype PII filter on 1–2 examples</li>
    </ul>
  </div>

  <!-- Reading Report -->
  <h4 class="title is-5 mt-2 mb-3">Reading Report (Due 10/10)</h4>
  <div class="content">
    <p><strong>Summarize &amp; critique:</strong> 2–3 sentence summary + 1 strength + 1 weakness.</p>
    <div class="columns">
      <div class="column">
        <p class="has-text-weight-semibold mb-2">Connect</p>
        <ul>
          <li>How do inference attacks differ from training-data extraction?</li>
          <li>What heuristic filter could an LLM app use to detect/block PII leakage?</li>
          <li>Does your dataset have PII-like strings? If so, what is your filtering strategy?</li>
        </ul>
      </div>
      <div class="column">
        <p class="has-text-weight-semibold mb-2">Discussion</p>
        <ul>
          <li>Give one scenario where sharing info is fine in one context but harmful in another.</li>
        </ul>
      </div>
    </div>
  </div>

  <hr class="my-5">

  <!-- Coding Assignment -->
  <h4 class="title is-5 mb-2">Coding Assignment 4: Prototype PII Filtering</h4>
  <p class="mb-4"><strong>Goal:</strong> Implement a basic PII-detection and redaction step to practice text preprocessing for privacy protection.</p>

  <div class="box p-4 mb-4" style="background:white;">
    <h5 class="title is-6 mb-3">Requirements</h5>
    <div class="content">
      <ul>
        <li><strong>Dataset:</strong> use your project dataset; it should already contain synthetic PII-like fields.</li>
        <li><strong>Detector:</strong> implement regex + simple checks for classes:
          <span class="is-family-monospace">EMAIL, PHONE, CREDIT_CARD, DATE/DOB, NAME, IP</span>.
        </li>
        <li><strong>Three redaction modes:</strong>
          <ul>
            <li><em>Strict mask</em> (e.g., <code>[EMAIL]</code>, <code>[PHONE]</code>)</li>
            <li><em>Partial mask</em> (e.g., <code>***-**-1234</code>, <code>j***@example.com</code>)</li>
            <li><em>LLM mask</em> (feed your data to an LLM and let it filter out PIIs for you.)</li>
          </ul>
        </li>
        <li><strong>Evaluation:</strong>
          <ul>
            <li>Precision / Recall / F1 <em>per class</em> (+ micro overall)</li>
            <li><strong>Residual leakage rate:</strong> % of docs with any missed high-risk item (CREDIT_CARD/SSN-like)</li>
            <li>Add ≥ 5 adversarial cases (e.g., spaced digits, leetspeak, Unicode confusables, inserted dots) and report catches vs. misses</li>
          </ul>
        </li>
      </ul>
    </div>
  </div>

  <!-- Deliverables -->
  <div class="box p-4" style="background:white;">
    <h5 class="title is-6 mb-3">Deliverables (GitHub)</h5>
    <div class="content">
      <ul>
        <li><strong>Code</strong> for detector + redaction + evaluation</li>
        <li><strong>README</strong> including:
          <ul>
            <li><strong>Dataset:</strong> which fields contain PII-like strings</li>
            <li><strong>Design &amp; implementation:</strong> detector patterns and validation checks</li>
            <li><strong>Redaction modes:</strong> 2–3 concrete examples</li>
            <li><strong>Results:</strong> P/R/F1 per class, residual leakage, (optional) Δutility, runtime</li>
            <li><strong>Adversarial tests:</strong> what was caught vs. missed; known failure modes</li>
            <li><strong>Implications:</strong> where this is sufficient vs. risky for your project</li>
          </ul>
        </li>
      </ul>
    </div>
  </div>
</section>

<section id="week7-assignment5" class="box p-5 mb-6" style="background:#f8fafc; border-left:4px solid var(--accent-color);">
  <header class="is-flex is-justify-content-space-between is-align-items-center mb-3">
    <h3 class="title is-4 mb-0">Week 6 — Assignment 5: Contextual Integrity</h3>
    <span class="tag is-success is-light is-medium">Presentation Wed 10/22 · Report & Code Due Fri 10/17 · 11:59 PM ET</span>
  </header>

  <!-- At a glance -->
  <div class="columns is-variable is-5 mb-4">
    <div class="column is-6">
      <div class="box p-4" style="background:white;">
        <h4 class="title is-6 mb-3">At a Glance</h4>
        <ul class="mb-2">
          <!-- <li>📖 <a href="https://arxiv.org/abs/2310.07298" target="_blank">Beyond Memorization: Violating Privacy via Inference with LLMs</a></li> -->
          <li>📖  1: <a href="https://arxiv.org/abs/2310.17884">Can LLMs Keep a Secret? Testing Privacy Implications of Language Models via Contextual Integrity Theory</a></li>
          <li>📖  2: <a href="https://arxiv.org/abs/2405.05175">AirGapAgent: Protecting Privacy-Conscious Conversational Agents</a></li>

          <li>Focus: how to build AI Agents that protect privacy.</li>
        </ul>
        <p class="mb-1"><strong>What to submit:</strong></p>
        <ul class="mt-1">
          <li>Slide deck (present in class 10/22)</li>
          <li>Reading report (PDF) → Gradescope</li>
          <li>Code + README → GitHub repo</li>
        </ul>
      </div>
    </div>
    <div class="column is-6">
      <div class="box p-4" style="background:white;">
        <h4 class="title is-6 mb-3">Timeline</h4>
        <ul>
          <li><strong>Wed 10/22 (in class):</strong> 1–2 min presentation + quick demo</li>
          <li><strong>Fri 10/17 11:59 PM ET:</strong> reading report + code + README due</li>
        </ul>
      </div>
    </div>
  </div>

  <!-- Presentation -->
  <h4 class="title is-5 mt-2 mb-3">In-Class Presentation (10/22)</h4>
  <div class="content">
    <ul>
      <li><strong>Summary:</strong> what is contextual integrity</li>
      <li><strong>Connection:</strong> how does contextual integrity relate to privacy in AI agents?</li>
      <li><strong>Code demo:</strong> show agentic interactions
      protecting user privacy</li>
    </ul>
  </div>

  <!-- Reading Report -->
  <h4 class="title is-5 mt-2 mb-3">Reading Report (Due 10/17)</h4>
  <div class="content">
    <p><strong>Summarize &amp; critique:</strong> 2–3 sentence summary + 1 strength + 1 weakness.</p>
    <div class="columns">
      <div class="column">
        <p class="has-text-weight-semibold mb-2">Connect</p>
        <ul>
          <li>What are unique challenges in building
          privacy-preserving AI agents?</li>
          <li>Is Contextual Integrity sufficient for ensuring privacy
          in AI agent at inference time?</li>
          <li>What are challenges of operationalizing Contextual
          Integrity for AI Agents?</li>
        </ul>
      </div>
      <div class="column">
        <p class="has-text-weight-semibold mb-2">Discussion</p>
        <ul>
          <li>Future autonomous AI Agents will likely be able to do
          things on user's behalf without checking with them.
          How would you design these agents to ensure they respect
          user privacy? Would you focus on system-level defenses,
          model-level defenses, or both?</li>
        </ul>
      </div>
    </div>
  </div>

  <hr class="my-5">

  <!-- Coding Assignment -->
  <h4 class="title is-5 mb-2">Coding Assignment 5: Contextual Integrity</h4>
  <p class="mb-4"><strong>Goal:</strong> Implement 5 different
  scenarios of using an AI agent for your startup. Generate more
  synthetic data if needed. Implement attacks trying to trick the
  agent and an Air Gap defense.</p>

  <div class="box p-4 mb-4" style="background:white;">
    <h5 class="title is-6 mb-3">Requirements</h5>
    <div class="content">
      <ul>
        <li><strong>Dataset:</strong> use your project dataset;
        augment if needed for synthetic conversations.</li>
        <li>Create 5 different scenarios of using an AI agent for your startup.
        </li>
        <li>Implement attacks that try to trick the agent. Implemented
        automated techniques to generate context hijacking.</li>
        <li>Compute & report the success rate of the attacks.</li>
        <li>Implement the Air Gap defense and show how it mitigates the attacks.</li>
      </ul>
    </div>
  </div>

  <!-- Deliverables -->
  <div class="box p-4" style="background:white;">
    <h5 class="title is-6 mb-3">Deliverables (GitHub)</h5>
    <div class="content">
      <ul>
        <li><strong>Dataset</strong> scenarios, user data, and any
        prompts used (attacks, defenses)</li>
        <li><strong>Code</strong> agent interactions</li>
        <li><strong>README</strong> including:
          <ul>
            <li><strong>Dataset:</strong> What type of scenarios are
            included? What attacks were attempted? What was private
            user data?</li>
            <li><strong>Design &amp; implementation:</strong> Both
            attack design and defense designs. How did you implement
            dynamic attacks.</li>
            <li><strong>Metrics:</strong> How did you measure privacy
            and utility?</li>
            <li><strong>Results:</strong>Privacy and utility tradeoff
            with different attack strategies and defenses.</li>
            
            <li><strong>Discussion:</strong> Limitations and future
            work for your design.</li>
          </ul>
        </li>
      </ul>
    </div>
  </div>
</section>

<section id="week8-assignment6" class="box p-5 mb-6" style="background:#f8fafc; border-left:4px solid var(--accent-color);">
  <header class="is-flex is-justify-content-space-between is-align-items-center mb-3">
    <h3 class="title is-4 mb-0">Week 8 — Assignment 6: Jailbreaks &amp; Prompt Injections</h3>
    <span class="tag is-success is-light is-medium">Presentation Wed 10/22 · Report &amp; Code Due Fri 10/24 · 11:59 PM ET</span>
  </header>

  <!-- At a glance -->
  <div class="columns is-variable is-5 mb-4">
    <div class="column is-6">
      <div class="box p-4" style="background:white;">
        <h4 class="title is-6 mb-3">At a Glance</h4>
        <ul class="mb-2">
          <li>📖 <a href="https://arxiv.org/abs/2307.15043" target="_blank">Universal and Transferable Adversarial Attacks on Aligned Language Models</a></li>
          <li>📖 <a href="https://arxiv.org/abs/2302.12173" target="_blank">Not What You Signed Up For: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection</a></li>
          <li>Focus: universal adversarial strings; indirect prompt injection in the wild; where your product is exposed (inputs, tools, browsing, integrations).</li>
        </ul>
        <p class="mb-1"><strong>What to submit:</strong></p>
        <ul class="mt-1">
          <li>Slide deck (present in class 10/22)</li>
          <li>Reading report (PDF) → Gradescope</li>
          <li>Code + README → GitHub repo</li>
        </ul>
      </div>
    </div>
    <div class="column is-6">
      <div class="box p-4" style="background:white;">
        <h4 class="title is-6 mb-3">Timeline</h4>
        <ul>
          <li><strong>Wed 10/22 (in class):</strong> short team presentation + demo</li>
          <li><strong>Fri 10/24 11:59 PM ET:</strong> reading report + code + README due</li>
        </ul>
      </div>
    </div>
  </div>

  <!-- Reading Report -->
  <h4 class="title is-5 mt-2 mb-3">Reading Report (Due 10/24)</h4>
  <div class="content">
    <p><strong>Summarize &amp; critique:</strong> 2–3 sentence summary + 1 strength + 1 weakness.</p>
    <div class="columns">
      <div class="column">
        <p class="has-text-weight-semibold mb-2">Connect</p>
        <ul>
          <li>Compare adversarial prompts to vision adversarial examples. What is easier to exploit? Why is that more vulnerable?</li>
          <li>How does indirect prompt injection differ from direct jailbreak attacks?</li>
          <li>What is your strategy for defending your system against these attacks?</li>
          <li>In what attack scenario is your system exposed to an indirect prompt injection? Why would an adversary do it? What capability does the attacker have, and what is the attacker’s gain?</li>
        </ul>
      </div>
      <div class="column">
        <p class="has-text-weight-semibold mb-2">Discussion</p>
        <ul>
          <li>Are alignment guardrails fundamentally brittle to adversarial prompting?</li>
          <li>Should defenses target the LLM, the application layer, or both?</li>
        </ul>
      </div>
    </div>
  </div>

  <hr class="my-5">

  <!-- Coding Assignment -->
  <h4 class="title is-5 mb-2">Coding Assignment 6: Jailbreak &amp; Prompt Injection Suite</h4>
  <p class="mb-4"><strong>Goal:</strong> Create at least one jailbreak prompt and one prompt-injection payload, evaluate success against your system or prototype, and demonstrate at least one successful defense against each.</p>

  <div class="box p-4 mb-4" style="background:white;">
    <h5 class="title is-6 mb-3">Requirements</h5>
    <div class="content">
      <ul>
        <li><strong>Attack harness:</strong> design dynamic jailbreak
        strings (implement GCG) and prompt injection payloads (e.g., from
        web content or hidden instructions).</li>
        <li><strong>Working jailbreak:</strong> provide the exact prompt, model/app tested, and evidence of success.</li>
        <li><strong>Working prompt injection:</strong> provide the source content (snippet or doc), how it was injected, and evidence of success.</li>
        <li><strong>Evaluation metric:</strong> define success (e.g., restricted content generated, attacker instruction executed, or sensitive info leaked).</li>
        <li><strong>Defense:</strong> add ≥1 mechanism (input filtering, retrieval allowlist, prompt rewriting/sanitization, tool scoping).</li>
        <li><strong>Report rates:</strong> attack success rate before and after defense, including examples of successful attacks.</li>
      </ul>
    </div>
  </div>

  <!-- Deliverables -->
  <div class="box p-4" style="background:white;">
    <h5 class="title is-6 mb-3">Deliverables (GitHub)</h5>
    <div class="content">
      <ul>
        <li><strong>Code</strong> + <strong>README</strong></li>
      </ul>
      <p class="mb-2"><strong>README can include:</strong></p>
      <ul>
        <li><strong>Design &amp; Implementation:</strong> attack and defense designs, including how you implemented dynamic (adaptive) attacks.</li>
        <li><strong>Metrics &amp; Results:</strong> success criteria and quantitative metrics for attack strategies and defenses (include success rates + brief analysis).</li>
        <li><strong>Discussion:</strong> limitations (in attack or defense), open challenges, and possible future improvements to your system or defense design.</li>
      </ul>
    </div>
  </div>
</section>

<section id="week9-assignment7" class="box p-5 mb-6" style="background:#f8fafc; border-left:4px solid var(--accent-color);">
  <header class="is-flex is-justify-content-space-between is-align-items-center mb-3">
    <h3 class="title is-4 mb-0">Week 9 — Assignment 7: Multi-modal attacks</h3>
    <span class="tag is-success is-light is-medium">Presentation Wed 10/29 · Report &amp; Code Due Fri 10/31 · 11:59 PM ET</span>
  </header>

  <!-- At a glance -->
  <div class="columns is-variable is-5 mb-4">
    <div class="column is-6">
      <div class="box p-4" style="background:white;">
        <h4 class="title is-6 mb-3">At a Glance</h4>
        <ul class="mb-2">
          <li>📖 <a href="https://arxiv.org/abs/2306.15447" target="_blank">Are aligned neural networks adversarially aligned?</a></li>
          <li>📖 <a href="https://arxiv.org/abs/2407.08970"
          target="_blank">Self-interpreting Adversarial Images</a></li>

          <li>Focus: multi-modal attacks</li>
        </ul>
        <p class="mb-1"><strong>What to submit:</strong></p>
        <ul class="mt-1">
          <li>Slide deck (present in class 10/29)</li>
          <li>Reading report (PDF) → Gradescope</li>
          <li>Code + README → GitHub repo</li>
        </ul>
      </div>
    </div>
    <div class="column is-6">
      <div class="box p-4" style="background:white;">
        <h4 class="title is-6 mb-3">Timeline</h4>
        <ul>
          <li><strong>Wed 10/29 (in class):</strong> short team presentation + demo</li>
          <li><strong>Fri 10/31 11:59 PM ET:</strong> reading report + code + README due</li>
        </ul>
      </div>
    </div>
  </div>

  <!-- Reading Report -->
  <h4 class="title is-5 mt-2 mb-3">Reading Report (Due 10/29)</h4>
  <div class="content">
    <p><strong>Summarize &amp; critique:</strong> 2–3 sentence summary + 1 strength + 1 weakness.</p>
    <div class="columns">
      <div class="column">
        <p class="has-text-weight-semibold mb-2">Connect</p>
        <ul>
          <li>What are key properties of multi-modal attacks?</li>
          <li>Why images are easier to attack than text?</li>
          <li>What is the key challenge of aligning modalities?</li>
        
        </ul>
      </div>
      <div class="column">
        <p class="has-text-weight-semibold mb-2">Discussion</p>
        <ul>
          <li>What are potential defenses against multi-modal
          attacks?</li>
        </ul>
      </div>
    </div>
  </div>

  <hr class="my-5">

  <!-- Coding Assignment -->
  <h4 class="title is-5 mb-2">Coding Assignment 7: Multi-modal attacks</h4>
  <p class="mb-4"><strong>Goal:</strong> Explore and evaluate multi-modal attacks on aligned language models.</p>

  <div class="box p-4 mb-4" style="background:white;">
    <h5 class="title is-6 mb-3">Requirements</h5>
    <div class="content">
      <ul>
        <li><strong>Task:</strong> Implement the multi-modal attack
        method from <a href="https://arxiv.org/abs/2306.15447">Are
        aligned neural networks adversarially aligned?</a>.</li>
        <li><strong>Dataset:</strong> use your project dataset;
        augment if needed for synthetic multi-modal data. Create 5
        examples of the attack.</li>
        <li>Evaluate the attack success rate on a set of prompts.</li>
        <li>Implement at least one defense mechanism and show
        how it mitigates the attack.</li>
        <li>Report the attack success rate before and after
        defense, including examples of successful attacks.</li>
      </ul>
    </div>
  </div>

  <!-- Deliverables -->
  <div class="box p-4" style="background:white;">
    <h5 class="title is-6 mb-3">Deliverables (GitHub)</h5>
    <div class="content">
      <ul>
        <li><strong>Code</strong> + <strong>README</strong></li>
      </ul>
      <p class="mb-2"><strong>README can include:</strong></p>
      <ul>
        <li><strong>Design &amp; Implementation:</strong> attack and defense designs, including how you implemented dynamic (adaptive) attacks.</li>
        <li><strong>Metrics &amp; Results:</strong> success criteria and quantitative metrics for attack strategies and defenses (include success rates + brief analysis).</li>
        <li><strong>Discussion:</strong> limitations (in attack or defense), open challenges, and possible future improvements to your system or defense design.</li>
      </ul>
    </div>
  </div>
</section>


    <!-- POLICIES SECTION -->
<h2 class="title is-4 mt-6" id="policies">Course Policies</h2>


<div class="box policy-box p-5 mb-5">
<h3 class="title is-5 mb-3" id="grade-scale">Course Grade Scale <span class="has-text-weight-normal">(100–499)</span></h3>
<div class="content">
<table class="table is-striped is-fullwidth grade-scale">
<thead>
<tr><th>Grade</th><th>Range</th><th>Grade</th><th>Range</th></tr>
</thead>
<tbody>
<tr><td>A</td><td>95–100</td><td>B</td><td>83–86</td></tr>
<tr><td>A-</td><td>90–94</td><td>B-</td><td>80–82</td></tr>
<tr><td>B+</td><td>87–89</td><td>C+</td><td>77–79</td></tr>
<tr><td>C</td><td>73–76</td><td>C-</td><td>70–72</td></tr>
<tr><td>D+</td><td>67–69</td><td>D</td><td>63–66</td></tr>
<tr><td>F</td><td>0–62</td><td></td><td></td></tr>
</tbody>
</table>
<p class="is-size-7 has-text-grey">Note: If your course uses a total-points basis (e.g., 499 pts), the letter-grade cutoffs are applied to the percentage earned.</p>
</div>
</div>


<div class="box policy-box p-5 mb-5">
<h3 class="title is-5 mb-3" id="ai-use">Notes on AI Use</h3>
<div class="content">
<p>You may use AI tools to help with reading or drafting, but you must fully understand the material and be able to explain it clearly to your teammates. The goal is to enrich group learning and class discussion—not just to generate text. You need to provide the <em>“How I used AI”</em> section in your report.</p>
</div>
</div>


<div class="box policy-box p-5 mb-5">
<h3 class="title is-5 mb-3" id="late-policy">Late Policy</h3>
<div class="content">
<p>Each assignment includes two late days (24 hours) that may be used without penalty. Late days do not accumulate across assignments—unused late days expire. Assignments submitted beyond the allowed late day will not be accepted unless prior arrangements are made due to documented emergencies.</p>
</div>
</div>


<div class="box policy-box p-5 mb-5">
<h3 class="title is-5 mb-3" id="nondiscrimination">Nondiscrimination Policy</h3>
<div class="content">
<p>This course is committed to fostering an inclusive and respectful learning environment. All students are welcome, regardless of age, background, citizenship, disability, education, ethnicity, family status, gender, gender identity or expression, national origin, language, military experience, political views, race, religion, sexual orientation, socioeconomic status, or work experience. Our collective learning benefits from the diversity of perspectives and experiences that students bring. Any language or behavior that demeans, excludes, or discriminates against members of any group is inconsistent with the mission of this course and will not be tolerated.</p>
<p>Students are encouraged to discuss this policy with the instructor or TAs, and anyone with concerns should feel comfortable reaching out.</p>
</div>
</div>


<div class="box policy-box p-5 mb-5">
<h3 class="title is-5 mb-3" id="academic-integrity">Academic Integrity</h3>
<div class="content">
<p>All work in this course is designated as group work, with shared responsibility among members. While assignments will be submitted jointly and receive a group grade, each member is expected to contribute meaningfully and to track individual contributions within the group.</p>
<p>Collaboration within your group is encouraged and expected. You may discuss ideas, approaches, and strategies with others, but all written material, whether natural language or code, must be the original work of your group. Copying text or code from external sources without proper attribution is a violation of academic integrity.</p>
<p>This course follows the <a herf="https://www.umass.edu/studentsuccess/academic-integrity">UMass Academic Honesty Policy and Procedures</a>. Acts of academic dishonesty, including plagiarism, unauthorized use of external work, or misrepresentation of contributions, will not be tolerated and may result in serious sanctions.</p>
<p>If you are ever uncertain about what constitutes appropriate collaboration or attribution, please ask the instructor or TAs before submitting your work.</p>
</div>
</div>


<div class="box policy-box p-5 mb-5">
<h3 class="title is-5 mb-3" id="accommodations">Accommodation Statement</h3>
<div class="content">
<p>The University of Massachusetts Amherst is committed to providing an equal educational opportunity for all students. If you have a documented physical, psychological, or learning disability on file with Disability Services (DS), you may be eligible for reasonable academic accommodations to help you succeed in this course. If you have a documented disability that requires an accommodation, please notify me within the first two weeks of the semester so that we may make appropriate arrangements. For further information, please visit <a href="https://www.umass.edu/disability/" target="_blank" rel="noopener">Disability Services</a>.</p>
</div>
</div>


<div class="box policy-box p-5 mb-6">
<h3 class="title is-5 mb-3" id="title-ix">Title IX Statement (Non-Mandated Reporter Version)</h3>
<div class="content">
<p>In accordance with Title IX of the Education Amendments of 1972 that prohibits gender-based discrimination in educational settings that receive federal funds, the University of Massachusetts Amherst is committed to providing a safe learning environment for all students, free from all forms of discrimination, including sexual assault, sexual harassment, domestic violence, dating violence, stalking, and retaliation. This includes interactions in person or online through digital platforms and social media. Title IX also protects against discrimination on the basis of pregnancy, childbirth, false pregnancy, miscarriage, abortion, or related conditions, including recovery.</p>
<p>There are resources here on campus to support you. A summary of the available Title IX resources (confidential and non-confidential) can be found at the following link: <a href="https://www.umass.edu/titleix/resources" target="_blank" rel="noopener">https://www.umass.edu/titleix/resources</a>. You do not need to make a formal report to access them. If you need immediate support, you are not alone. Free and confidential support is available 24/7/365 at the SASA Hotline <strong>413-545-0800</strong>.</p>
</div>
</div>


</div>



        </div>
    </section>
    <footer class="footer">
        <div class="content has-text-centered">
            <p>© UMass Amherst • CS690 Trustworthy and Responsible AI • Last updated June 2025</p>
        </div>
    </footer>
    <script>
        // Simple nav highlight on click
        document.querySelectorAll('.nav-item').forEach(item => {
            item.addEventListener('click', function(e) {
                document.querySelectorAll('.nav-item').forEach(i => i.classList.remove('active'));
                this.classList.add('active');
            });
        });
        
        // Assignment sidebar navigation
        document.querySelectorAll('.assignment-nav-link').forEach(link => {
            link.addEventListener('click', function(e) {
                document.querySelectorAll('.assignment-nav-link').forEach(l => l.classList.remove('active'));
                this.classList.add('active');
            });
        });
        
        // Highlight active assignment on scroll
        const assignmentSections = document.querySelectorAll('[id^="week"]');
        const assignmentLinks = document.querySelectorAll('.assignment-nav-link');
        
        function highlightActiveAssignment() {
            let current = '';
            
            assignmentSections.forEach(section => {
                const sectionTop = section.offsetTop;
                const sectionHeight = section.clientHeight;
                if (pageYOffset >= (sectionTop - 150)) {
                    current = section.getAttribute('id');
                }
            });
            
            assignmentLinks.forEach(link => {
                link.classList.remove('active');
                if (link.getAttribute('href') === '#' + current) {
                    link.classList.add('active');
                }
            });
        }
        
        window.addEventListener('scroll', highlightActiveAssignment);
        window.addEventListener('load', highlightActiveAssignment);
    </script>
</body>
</html>
